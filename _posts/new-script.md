Several years ago, I had generated a new linguiitic stript using Gaussian Processes -- the idea was very simple, I had a 2-dimensional gaussian process in X and Y coordinates that combined two independent GPs, and used a fixed covariance kernel. Now, in the age of Diffusion Models (or formally, Denoising Diffusion Probabilistic Models), it is tempting to revisit this problem by feeding a large dataset of alphabetical and numerical characters as images, and then asking a trained model to produce new ones. To do this, I created a minimalist implementation of a DDPM and curated some data. 
