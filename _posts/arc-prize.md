Announced earlier this week. 
ARC supposedly measures general intelligence, as opposed to many other menchmarks which are more easily gamed by LLMs. 
Here is a podcast I listedn to with Chollet, the creator of the ARC benchmark, who proposed ARC in 2019, before the LLM revolution of the past 4 years. 
Chollet says: 
- LLMs engage in Type 1 learning, while true intelligence is Type 2. 
- He quotes John Piaget: `Intelligence is what you do when you don't know what to do.` That is, you don't have a template to respond to the situation, so you must reason from first principles and come up with a response. 
- LLMs are still (tremendously) valuable and scaling them up makes them even more valuable. But scaling up type 1 does not lead to type 2. 
- Humans are typically engaged in a mix of type 1 and type 2 intelligence. 
- LLMs are a static trained model: unlike humans, who are constantly learning. 
- Test time learning is a thing: that is, LLMs can be made to fine tune at test time. This makes them dynamic. This is an approach taken by Jack Cole. That approach is the current best on the ARC benchmark. 
- Designing a system for Type 2 is much harder. 
- He thinks doing well on ARC will require a combination of Type 1 and Type 2. 
- He differentiates between intelligence and skill. LLMs have skill but not intelligence. 
- The current attention grabbed by LLMs has sucked the oxygen from the room when it comes to AGI research. 
- He hopes that this contest will spur progress in true AGI.

A number of people have reacted to the $1M prize with the sentiment that the monetary reward attached to this is way too small. That is, if someone were truly able to solve type 2, then its economic value would be 100-10000x more than that. 
My reactions: 
- I agree with the assertion that LLMs are Type 1. That is LLMs work well when the situation is similar to what they have encountered before. 
