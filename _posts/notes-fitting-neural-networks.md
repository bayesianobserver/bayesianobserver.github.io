
My notes on training neural networks. 

- In most cases, frame the loss using a likelihood. For example: 
 - Regression:
 - Classification: 
- Tips and tricks: 
 - Make sure you know the data very well: are the features stationary? Outliers? 
- Optimizers:
 - SGD: 
 - Adam:
 - AdamW: 
- Weight decay: 
- Batches:  
 - Batch size: 
- Normalization approaches: 
 - LayerNorm
 - BatchNorm
- Dropout: 
- Early stopping: 
- The use of GPUs: 
 - Multiple GPUs
- Hyperparameter tuning: 
 - Can I use a smaller dataset for hyper-parameter search?
- What if data is not IID? 
- Dataset and Dataloader:
